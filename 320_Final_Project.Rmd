---
title: "Video Game Popularity Formula: An Analysis for Video Games Sales"
output:
  html_document: default
  pdf_document: default
---

## Student Names: Qiuqi Gao, Ziqing Ji, Minfeng Wu

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1germd702wxj30lb0e70u5.jpg)


```{r setup, include=FALSE}
### load packages and read data

knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('reshape2')
library('MASS')
```


## Motivation 

During the recent COVID-19 pandemic, there is a surge in video game sales. The entertainment business has sprung into action to capture people attention. According to economist, reports from Italy and South Korea suggest that the number of people who watch television each day is up 12% and 17% respectively. 
Nintendo sold 13.41 million copies of the game worldwide in its first six weeks of release, which covers the period through the end of April. There are more and more connections between the virtual world and real life: “Grand Theft Auto” last year allows players to hang out at virtual casinos while using real money (several countries banned this feature). A community of Minecraft players in China recently recreated the hospitals built in Wuhan following the COVID-19 outbreak, in a tribute to the builders and hospital workers on the front line.  

As a group of video game players, we want to dig into the video game world and find how it reflects the real world. As data scientists, we want to examine whether there is any trend to lead games to achieve business success. We want to check their ratings, genre, score, and sale markets. Essentially, we intend to find a formula with these correlating factors. Thus, we could predict game sales over our instinct or biased critics.


## I. Data Collection

We use this dataset fromR for Data Science online learning
community:https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings). This dataset contains a list of video games with
sales, platform, gener and users score.etc

- Critic_score : Aggregate score compiled by Metacritic staff
- Criticcount : The number of critics used in coming up with the Criticscore
- User_score : Score by Metacritic's subscribers
- Usercount : Number of users who gave the userscore
- Developer : Party responsible for creating the game
- Rating : The ESRB ratings

```{r}
sales_df <- read.csv('/Users/apple/Desktop/Video_Games_Sales_as_at_22_Dec_2016.csv', as.is = TRUE)
nrows <- dim(sales_df)[1]
```


## II. Data preprocessing and Exploratory data analysis


#### Checking data types

For our analysis, we will first force the attributes of releasing years and users' score into numeric data type. 

```{r}
summary(sales_df)

sales_df$Year_of_Release <- as.numeric(sales_df$Year_of_Release)
sales_df$User_Score <- as.numeric(sales_df$User_Score)

```



#### Missing values: remove rows with missing Year_of_Release

And we will drop any rows that has a mssing data for the attribute Year_of_Release, because it is a important imformation for our analysis and those data points won't contribute to our analysis. Now that we have tidied and processed the data, we can proceed to the next step of the data science pipeline.

```{r}
colSums(is.na(sales_df))
sales_df <- sales_df[!is.na(sales_df$Year_of_Release), ]
sales_df[sales_df$Rating == '', 'Rating'] = 'Unknown'
sales_df[sales_df$Genre == '', 'Genre'] = 'Unknown'
sales_df[sales_df$Developer == '', 'Developer'] = 'Unknown'
nrows <- dim(sales_df)[1]

```



#### Checking categorical variables and correlations

Then we set tables regards of platform vs Genre, publisher vs genre and generally ratting, the table helps us understand does the platform and publisher has the relationship with the game genre.

```{r}
table(sales_df[ , c('Platform', 'Genre')])
table(sales_df[ , c('Publisher', 'Genre')])
table(sales_df$Rating)

```



#### Cheking numerical variables and correlations

Then we list out the the coorelations of religion sales and the generally evaluate information for games. 
```{r}
cor(sales_df[ , c('NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales')])
cor(
  sales_df[!is.na(sales_df$User_Count) & !is.na(sales_df$Critic_Count),
  c('User_Score', 'User_Count', 'Critic_Score', 'Critic_Count')]
)

```



## III. Exploratory Analysis and Data Visualization



#### Correlation of rating and user score / count

Then we make boxplot to visualized the relationship between rating vs User_Score, Rating vs User_Count, Genre vs User_Score as well as Genre vs User_Count. For the rating vs User_Score, we noticed that rating E(everyone) has a wider spread of user score, but comparetly smaller mean of User_Count. Rating M has a bigger spread of User_Count and comperatly higher mean of User_Count. For the plot of genre, we notice that differnt religions have different preferation of game genre regards of User_Score. But the mean of User_Count is comparetly low inside of each religions.

```{r}
ggplot(sales_df) +
  geom_boxplot(aes(x = Rating, y = User_Score))

ggplot(sales_df) +
  geom_boxplot(aes(x = Rating, y = log(User_Count)))

ggplot(sales_df) +
  geom_boxplot(aes(x = Genre, y = User_Score, color = Rating))

ggplot(sales_df) +
  geom_boxplot(aes(x = Genre, y = log(User_Count), color = Rating))


```



#### Sales summary on different areas

Then we have a summary of games sales regards of years in each areas. We noticed that the sales of game are remained low from 1980 to 1995 and start to  increase until 2007/2008. Then the sales start to decrease until 2020. 

```{r}
sales_summary <- sales_df %>%
  group_by(Year_of_Release) %>%
  summarise(
    na_sales = sum(NA_Sales),
    eu_sales = sum(EU_Sales),
    jp_sales = sum(JP_Sales),
    other_sales = sum(Other_Sales),
    total_sales = sum(Global_Sales)
  )
colSums(sales_summary)

sales_summary_long <- melt(sales_summary, id.vars = 'Year_of_Release')
ggplot(sales_summary_long) +
  geom_point(aes(x = Year_of_Release, y = value)) +
  geom_line(aes(x = Year_of_Release, y = value)) +
  facet_wrap( ~ variable, ncol = 2, scales = 'free_y') +
  labs(y = 'Sales')

```



#### Sales on different genre by years

Then we have graphs to see the relationship of number of games and years in each genre. We notice that all the lines has a similar trends with the previous graph. However, the action and misc genre has a greater increase and reach a higher peak in 2010.

```{r}
sales_df %>%
  group_by(Year_of_Release, Genre) %>%
  summarise(genre_count = n()) %>%
  ggplot() + 
  geom_line(aes(x = Year_of_Release, y = genre_count)) + 
  geom_point(aes(x = Year_of_Release, y = genre_count)) + 
  facet_wrap( ~ Genre, ncol = 4) +
  labs(y = 'Number of games')
```



#### Users on different platform by years

Then we have graphs to see the relationship of User_Count and years in each platforms. The trend lines are different for each platform and we notice that platform PC has the oldest develop history and has the highest count of user in 2010. The User_Count for all platform tend to decrease after realeasing for 5 years.

```{r}
sales_df[!is.na(sales_df$User_Count), ] %>%
  group_by(Year_of_Release, Platform) %>%
  summarise(total_user_count = sum(User_Count)) %>%
  ggplot() +
  geom_point(aes(x = Year_of_Release, y = total_user_count)) +
  geom_line(aes(x = Year_of_Release, y = total_user_count)) +
  facet_wrap( ~ Platform, ncol = 5, scales = 'free') + 
  labs(y = 'Total user count') +
  theme(axis.text.x = element_text(angle = 90))


```



#### User count on different genre by years

Then we have graphs to see the relationship of sales of games and years in each genre. We notice that all the lines has a similar tredns with each others. We notice that the genre of sports has smaller spread and jump and comparetly increased steadly. That suggest that other genre of games having a big jump when a big game was introduced, however, after the year of releasing, it might drop down a higehr number of sales. In contract, sports genre does not depend on if there is a big game introduced or not. 

```{r}
sales_df[!is.na(sales_df$User_Count), ] %>%
  group_by(Year_of_Release, Genre) %>%
  summarise(total_user_count = sum(User_Count)) %>%
  ggplot() +
  geom_point(aes(x = Year_of_Release, y = total_user_count)) +
  geom_line(aes(x = Year_of_Release, y = total_user_count)) +
  facet_wrap( ~ Genre, ncol = 4, scales = 'free') + 
  labs(y = 'Total user count') +
  theme(axis.text.x = element_text(angle = 90))

```



#### User score on different publishers

Then we make a histogram to see the relationship between user score and the publisher. We notice that most of the user_score concentrate around 7.5 and the range mostly concentrate between 5.0 to 8.0.

```{r}
sales_df[!is.na(sales_df$User_Score), ] %>%
  group_by(Publisher) %>%
  summarise(average_score = mean(User_Score)) %>%
  ggplot() +
  geom_histogram(aes(x = average_score, y = ..density..), bins = 50) +
  labs(x = 'Average User_Score of Publishers')

```



#### Checking normal distribution

We used the Shapiro-Wilk normality test to test whether the distributions of the sales are normal. By using the Shaprio normality test, we get a W value. And the Probability of being less than the W value is indicated as the p-value. The null hypothesis here is that the data are normally distributed. We chose alpha to be 0.05 in this case. Therefore, if the p-value is less than 0.05, it means that there exists deviations from normality. Else, the null hypothesis is not rejected and the data is normally distributes.

According to the results we obtianed, we see that the all of the p-values of all sales are less than 0.05, so we can see that all the sales are not normally distributed. Among the sales of different areas, we can see that the sales in apan are relatively more normal than the sales of other areas.

```{r}
shapiro.test(sales_summary$na_sales)
shapiro.test(sales_summary$eu_sales)
shapiro.test(sales_summary$jp_sales)
shapiro.test(sales_summary$total_sales)
shapiro.test(log(sales_summary$total_sales))
```


## IV. Analysis and ML

We will use the linear regression method to predict the total sales

First, we plotted histograms showing the relation between global sales and density.

```{r}
ggplot(sales_df) +
  geom_histogram(aes(x = Global_Sales, y = ..density..), bins = 100)

sales_df$Global_Sales_log <- log(sales_df$Global_Sales)
ggplot(sales_df) +
  geom_histogram(aes(x = Global_Sales_log, y = ..density..), bins = 50)
```


Next we get our training data.

```{r}
training_data <- sales_df[!is.na(sales_df$User_Count) & !is.na(sales_df$Critic_Count), ] 
training_data$Year_to_now <- 2020 - training_data$Year_of_Release
```


We then train our data.

In the output, there are specific annotations after the values we obtained. Those annotations represent the significance of the values and help us decide whether we should use them or not. They are devided into 5 groups: 1. "***" means that the value's p-value is in [0, 0.001], 2. "**" means that the value's p-value is in (0.001, 0.01], 3. "*" means that the value's p-value is in (0.01, 0.05] 4. "." means that the value's p-value is in (0.05, 0.1], else 4. the value's p-value is in (0.1, 1]. 

Since we only want the values that are significant, we only want the values that have a p-value that is less than 0.05. First we look at the intercept's p-value, the intercept's p-value is  0.023411(which is less than 0.05), which proves that the intercept is not 0 when x is 0. Then we look at the other p-values and we only extract the ones that are significant (not all are listed here): 
factor(Platform)DS                                                                                0.012347 *   
factor(Platform)PC                                                                                0.000930 ***
factor(Platform)PS                                                                                0.009216 ** 
factor(Platform)PS2                                                                               0.032391 *  
factor(Platform)PS3                                                                               0.007887 **   
factor(Platform)Wii                                                                               3.06e-08 ***
factor(Platform)WiiU                                                                              0.001273 **  
factor(Genre)Adventure                                                                            0.041605 *   
factor(Genre)Misc                                                                                 0.020381 *  
factor(Genre)Puzzle                                                                               0.002596 ** 
factor(Genre)Racing                                                                               0.034506 *   
factor(Genre)Sports                                                                               0.003617 ** 
factor(Genre)Strategy                                                                             0.010699 * 
etc.

In addition, the Residual standard error is the estimate value of the standard deviation of the response from the population regression line. The RSE here is 1.685 units. 

The R-squared varialble estimates the percentage of variability that is explained by the predictors in the response . Multiple R-squared value of this model is 0.4251 and the	Adjusted R-squared value of this model is 0.2567. Since the R-squared value 42.51% is relatively low, this shows that this model is not good at predicting global sales and that we shouldnt use this model to predict and analyze data. 
```{r}
model <- lm(
  Global_Sales ~ factor(Platform) + factor(Genre) + factor(Publisher) +
    Critic_Score + Critic_Count + User_Score + User_Count + factor(Developer) + 
    factor(Rating) + Year_to_now,
  data = training_data
)
summary(model)
```


In the following model, we only want the values that have p-values less than 0.05. First we look at the intercept's p-value, the intercept's p-value is  0.000228(which is less than 0.05), which proves that the intercept is not 0 when x is 0. 

We then extract the ones that are significant(not all are listed here): 
factor(Platform)GC                                                                                0.000115 ***
factor(Platform)PC                                                                                 < 2e-16 ***
factor(Platform)PS                                                                                3.92e-11 ***
factor(Platform)PS2                                                                               9.33e-07 ***
factor(Platform)PS3                                                                               5.83e-05 ***
factor(Platform)PSV                                                                               0.029497 *  
factor(Platform)Wii                                                                               5.52e-08 ***
factor(Platform)WiiU                                                                              4.55e-05 ***
factor(Platform)XB                                                                                5.23e-05 ***
factor(Genre)Adventure                                                                            0.000116 ***  
factor(Genre)Misc                                                                                 3.68e-05 ***
factor(Genre)Puzzle                                                                               0.000515 *** 
factor(Genre)Simulation                                                                           0.016592 *  
factor(Genre)Strategy                                                                             5.48e-07 ***
factor(Publisher)1C Company                                                                       0.038059 *  
etc.

In addition, the Residual standard error here is 0.8639 units, which suggests that this model makes relatively better predictions than the previous one.

The Multiple R-squared value of this model is 0.7079 and the Adjusted R-squared value of this model is 0.6224. Since the R-squared value 70.79% is relatively high and a lot better then the R-squeared value of the previous one, this shows that this model is relatively good at predicting and that we could probably use this model to predict and analyze data.

```{r}
log_model <- lm(
  Global_Sales_log ~ factor(Platform) + factor(Genre) + factor(Publisher) +
    Critic_Score + Critic_Count + User_Score + User_Count + factor(Developer) + 
    factor(Rating) + Year_to_now,
  data = training_data
)
summary(log_model)
```


## V. Insight

Our analysis overall reflected that specific game platforms and specific genres of games contribute more to the global sales as a whole. The prediction model takes the main factors into consideration but it is not accurate enough. There might be a lot moreother hidden factors that we did not take into consideration, so more research and closer analysis on the data is still needed in order to yield more accurate and usefule models that fit our data better and provides a more accurate prediction of the global sales. But overall, it is a relatively good model. In conclusion, the analysis we did in this reflects a lot of hidden, interesting patterns looking from the economic aspect of the games market.


# VI. Resources 
Our tutorial inspired by resources below:

1. Hector's note on data science: https://www.hcbravo.org/IntroDataSci/bookdown-notes/
2. Rstudio: https://rstudio.com/products/rstudio/
3. tidyverse: https://www.tidyverse.org/
4. scikit learn: https://scikit-learn.org/stable/index.html
5. ggplot http://ggplot.yhathq.com/
6. Kaggle:https://www.kaggle.com/